{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yalcindemir/Claude-to-Codellama-Distillation/blob/main/notebooks/Claude_Code_Model_Colab_Clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸš€ Claude-to-CodeLlama Knowledge Distillation\n",
    "\n",
    "**Transform Claude Opus 4's Superior Code Generation into an Accessible 7B Model**\n",
    "\n",
    "Bu notebook Claude Opus 4'den Code Llama 7B'ye bilgi damÄ±tÄ±mÄ±nÄ±n tam bir uÃ§tan uca implementasyonunu saÄŸlar.\n",
    "\n",
    "## ğŸ“‹ Ã–zellikler\n",
    "- ğŸ§  **Ã–ÄŸretmen-Ã–ÄŸrenci Ã–ÄŸrenme**: Claude Opus 4 â†’ Code Llama 7B\n",
    "- ğŸ’° **Maliyet Etkin**: Colab Pro eÄŸitimi iÃ§in ~$50-100\n",
    "- âš¡ **Bellek Etkin**: 6GB GPU iÃ§in QLoRA optimizasyonu\n",
    "- ğŸ“Š **KapsamlÄ± DeÄŸerlendirme**: HumanEval ve MBPP benchmarklarÄ±\n",
    "- ğŸ”§ **Ãœretim HazÄ±r**: EÄŸitilen modeli kaydet ve deploy et\n",
    "\n",
    "## ğŸ¯ Beklenen SonuÃ§lar\n",
    "- **HumanEval**: 70-75% pass@1 (vs 33.5% baseline)\n",
    "- **MBPP**: 65-70% pass@1 (vs 41.4% baseline)\n",
    "- **EÄŸitim SÃ¼resi**: Colab Pro'da 4-6 saat\n",
    "- **Toplam Maliyet**: API Ã§aÄŸrÄ±larÄ± dahil ~$60-80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ğŸ› ï¸ Ortam Kurulumu\n",
    "\n",
    "Ä°lk olarak ortamÄ± kuralÄ±m ve baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu_check"
   },
   "outputs": [],
   "source": [
    "# GPU durumunu kontrol et\n",
    "!nvidia-smi\n",
    "\n",
    "# Google Drive'Ä± kalÄ±cÄ± depolama iÃ§in baÄŸla\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Proje dizini oluÅŸtur\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/claude_distillation'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(f\"âœ… Ã‡alÄ±ÅŸma dizini: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_compatibility"
   },
   "outputs": [],
   "source": [
    "# ğŸš€ Colab Uyumluluk KontrolÃ¼ ve DÃ¼zeltme\n",
    "print(\"ğŸ” Colab ortamÄ± kontrol ediliyor...\")\n",
    "\n",
    "# Colab'da mÄ± Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±zÄ± kontrol et\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"âœ… Google Colab ortamÄ±nda Ã§alÄ±ÅŸÄ±yorsunuz\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"â„¹ï¸ Local ortamda Ã§alÄ±ÅŸÄ±yorsunuz\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Colab'da notebook uyumluluk sorunlarÄ±nÄ± Ã§Ã¶z\n",
    "    print(\"ğŸ”§ Colab uyumluluk sorunlarÄ± dÃ¼zeltiliyor...\")\n",
    "    \n",
    "    # Jupyter widgets sorunlarÄ±nÄ± Ã§Ã¶z\n",
    "    !pip install -q --upgrade ipywidgets\n",
    "    \n",
    "    # Notebook uyumluluk paketlerini gÃ¼ncelle  \n",
    "    !pip install -q --upgrade notebook>=6.4.12\n",
    "    \n",
    "    # Colab'da Ã§akÄ±ÅŸan paketleri dÃ¼zelt\n",
    "    !pip install -q --upgrade google-colab\n",
    "    \n",
    "    print(\"âœ… Colab uyumluluk dÃ¼zeltmeleri tamamlandÄ±\")\n",
    "\n",
    "print(\"ğŸ¯ Ortam hazÄ±rlÄ±k tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Kritik baÄŸÄ±mlÄ±lÄ±klarÄ± kur\n",
    "print(\"ğŸ“¦ Kritik baÄŸÄ±mlÄ±lÄ±klar kuruluyor...\")\n",
    "\n",
    "critical_deps = [\n",
    "    \"anthropic>=0.25.0\",\n",
    "    \"backoff>=2.2.1\", \n",
    "    \"pyyaml>=6.0\",\n",
    "    \"tqdm>=4.65.0\",\n",
    "    \"datasets>=2.14.0\",\n",
    "    \"bitsandbytes>=0.41.0\",\n",
    "    \"transformers>=4.35.0\",\n",
    "    \"accelerate>=0.24.0\",\n",
    "    \"peft>=0.6.0\",\n",
    "    \"torch>=2.0.0\"\n",
    "]\n",
    "\n",
    "for dep in critical_deps:\n",
    "    try:\n",
    "        !pip install -q {dep}\n",
    "        print(f\"âœ… {dep}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {dep} kurulumunda sorun: {e}\")\n",
    "\n",
    "# Ek Colab paketleri\n",
    "!pip install -q wandb evaluate scikit-learn\n",
    "\n",
    "print(\"ğŸ¯ BaÄŸÄ±mlÄ±lÄ±k kurulumu tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Repo'yu klonla ve kurulum yap\n",
    "if not os.path.exists('Claude-to-Codellama-Distillation'):\n",
    "    !git clone https://github.com/yalcindemir/Claude-to-Codellama-Distillation.git\n",
    "    print(\"âœ… Repository klonlandÄ±\")\n",
    "else:\n",
    "    print(\"âœ… Repository zaten mevcut\")\n",
    "\n",
    "# Proje dizinine geÃ§\n",
    "os.chdir('Claude-to-Codellama-Distillation')\n",
    "print(f\"ğŸ“‚ Proje dizini: {os.getcwd()}\")\n",
    "\n",
    "# Manual path setup (setup.py sorunlarÄ±nÄ± atlamak iÃ§in)\n",
    "import sys\n",
    "src_path = os.path.join(os.getcwd(), 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Kurulumu doÄŸrula\n",
    "if os.path.exists('./src'):\n",
    "    print(\"âœ… Manuel path kurulumu tamamlandÄ±\")\n",
    "    src_files = [f for f in os.listdir('./src') if f.endswith('.py')]\n",
    "    print(f\"ğŸ“„ Python dosyalarÄ±: {src_files}\")\n",
    "else:\n",
    "    print(\"âŒ src dizini bulunamadÄ±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ğŸ”‘ YapÄ±landÄ±rma\n",
    "\n",
    "API anahtarlarÄ±nÄ±zÄ± ve yapÄ±landÄ±rmanÄ±zÄ± ayarlayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "api_keys"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# API anahtarlarÄ±nÄ± ayarla\n",
    "print(\"ğŸ”‘ API anahtarlarÄ± ayarlanÄ±yor...\")\n",
    "\n",
    "# Claude API anahtarÄ± (gerekli)\n",
    "if not os.getenv('ANTHROPIC_API_KEY'):\n",
    "    anthropic_key = getpass('Anthropic API anahtarÄ±nÄ±zÄ± girin: ')\n",
    "    os.environ['ANTHROPIC_API_KEY'] = anthropic_key\n",
    "    print(\"âœ… Claude API anahtarÄ± ayarlandÄ±\")\n",
    "else:\n",
    "    print(\"âœ… Claude API anahtarÄ± zaten ayarlÄ±\")\n",
    "\n",
    "# Weights & Biases (isteÄŸe baÄŸlÄ±)\n",
    "if not os.getenv('WANDB_API_KEY'):\n",
    "    wandb_key = getpass('W&B API anahtarÄ±nÄ±zÄ± girin (isteÄŸe baÄŸlÄ±, atlamak iÃ§in Enter): ')\n",
    "    if wandb_key:\n",
    "        os.environ['WANDB_API_KEY'] = wandb_key\n",
    "        print(\"âœ… W&B API anahtarÄ± ayarlandÄ±\")\n",
    "    else:\n",
    "        print(\"â­ï¸ W&B atlandÄ±\")\n",
    "else:\n",
    "    print(\"âœ… W&B API anahtarÄ± zaten ayarlÄ±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_config"
   },
   "outputs": [],
   "source": [
    "# Colab Ã¶zel yapÄ±landÄ±rma\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# GPU kontrolÃ¼\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ® Cihaz: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "else:\n",
    "    print(\"âš ï¸ GPU bulunamadÄ± - eÄŸitim Ã§ok yavaÅŸ olacak!\")\n",
    "\n",
    "# Colab optimize edilmiÅŸ yapÄ±landÄ±rma\n",
    "COLAB_CONFIG = {\n",
    "    'target_size': 100,    # Demo iÃ§in kÃ¼Ã§Ã¼k dataset\n",
    "    'num_epochs': 1,       # HÄ±zlÄ± eÄŸitim\n",
    "    'batch_size': 1,       # Bellek iÃ§in kÃ¼Ã§Ã¼k batch\n",
    "    'max_length': 512,     # KÄ±sa diziler\n",
    "    'use_4bit': True,      # QLoRA quantization\n",
    "    'lora_r': 8,           # KÃ¼Ã§Ã¼k LoRA rank\n",
    "}\n",
    "\n",
    "print(\"âœ… Colab yapÄ±landÄ±rmasÄ± ayarlandÄ±\")\n",
    "print(f\"ğŸ“Š YapÄ±landÄ±rma: {COLAB_CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase1"
   },
   "source": [
    "## ğŸ“Š AÅŸama 1: Veri Seti OluÅŸturma\n",
    "\n",
    "Claude Opus 4 kullanarak yÃ¼ksek kaliteli kod Ã¶rnekleri oluÅŸturun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_modules"
   },
   "outputs": [],
   "source": [
    "# ModÃ¼lleri import et\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Kritik paketlerin mevcut olduÄŸunu kontrol et\n",
    "try:\n",
    "    import anthropic\n",
    "    import backoff\n",
    "    import yaml\n",
    "    import tqdm\n",
    "    import datasets\n",
    "    print(\"âœ… TÃ¼m kritik paketler mevcut\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Eksik paket: {e}\")\n",
    "    print(\"ğŸ”§ Eksik baÄŸÄ±mlÄ±lÄ±klar kuruluyor...\")\n",
    "    !pip install -q anthropic backoff pyyaml tqdm datasets\n",
    "    print(\"âœ… BaÄŸÄ±mlÄ±lÄ±klar kuruldu, runtime'Ä± yeniden baÅŸlatmanÄ±z gerekebilir\")\n",
    "\n",
    "# ModÃ¼l import'larÄ±nÄ± dene\n",
    "try:\n",
    "    from dataset_generator import DatasetGenerator, DatasetConfig\n",
    "    print(\"âœ… dataset_generator baÅŸarÄ±yla import edildi\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ dataset_generator import edilemedi: {e}\")\n",
    "    print(\"Dosya konumunu kontrol ediyoruz...\")\n",
    "    if os.path.exists('./src'):\n",
    "        print(f\"src iÃ§eriÄŸi: {os.listdir('./src')}\")\n",
    "\n",
    "try:\n",
    "    from claude_client import ClaudeConfig\n",
    "    print(\"âœ… claude_client baÅŸarÄ±yla import edildi\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ claude_client import edilemedi: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_sample_data"
   },
   "outputs": [],
   "source": [
    "# Import sorunlarÄ± varsa Ã¶rnek veri oluÅŸtur\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Veri dizinini oluÅŸtur\n",
    "data_dir = Path('./data/generated')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ã–rnek eÄŸitim verisi oluÅŸtur\n",
    "sample_train_data = [\n",
    "    {\n",
    "        \"instruction\": \"Write a Python function to calculate the factorial of a number\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"def factorial(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    return n * factorial(n - 1)\",\n",
    "        \"language\": \"python\",\n",
    "        \"tokens_used\": 25,\n",
    "        \"generation_time\": 1.2,\n",
    "        \"metadata\": {\"difficulty\": \"easy\"}\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Create a JavaScript function to reverse a string\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"function reverseString(str) {\\n    return str.split('').reverse().join('');\\n}\",\n",
    "        \"language\": \"javascript\",\n",
    "        \"tokens_used\": 20,\n",
    "        \"generation_time\": 0.8,\n",
    "        \"metadata\": {\"difficulty\": \"easy\"}\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Implement a binary search algorithm in Python\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"def binary_search(arr, target):\\n    left, right = 0, len(arr) - 1\\n    while left <= right:\\n        mid = (left + right) // 2\\n        if arr[mid] == target:\\n            return mid\\n        elif arr[mid] < target:\\n            left = mid + 1\\n        else:\\n            right = mid - 1\\n    return -1\",\n",
    "        \"language\": \"python\",\n",
    "        \"tokens_used\": 45,\n",
    "        \"generation_time\": 2.1,\n",
    "        \"metadata\": {\"difficulty\": \"medium\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Ã–rnek doÄŸrulama verisi\n",
    "sample_val_data = [\n",
    "    {\n",
    "        \"instruction\": \"Write a Python function to check if a number is prime\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"def is_prime(n):\\n    if n < 2:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\",\n",
    "        \"language\": \"python\",\n",
    "        \"tokens_used\": 35,\n",
    "        \"generation_time\": 1.5,\n",
    "        \"metadata\": {\"difficulty\": \"medium\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "# JSONL dosyalarÄ±nÄ± yaz\n",
    "with open(data_dir / 'train.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in sample_train_data:\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "with open(data_dir / 'validation.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in sample_val_data:\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"âœ… Ã–rnek veri seti oluÅŸturuldu\")\n",
    "print(f\"ğŸ“ EÄŸitim Ã¶rnekleri: {len(sample_train_data)}\")\n",
    "print(f\"ğŸ“ DoÄŸrulama Ã¶rnekleri: {len(sample_val_data)}\")\n",
    "print(f\"ğŸ“‚ Veri dizini: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase2"
   },
   "source": [
    "## ğŸ¯ AÅŸama 2: Model EÄŸitimi\n",
    "\n",
    "Bilgi damÄ±tÄ±mÄ± kullanarak Code Llama'yÄ± eÄŸitin."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "training_setup"
   },
   "outputs": [],
   "source": "# EÄŸitim baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ±n mevcut olduÄŸunu kontrol et\\ntry:\\n    import torch\\n    import transformers\\n    import peft\\n    import bitsandbytes\\n    print(\\\"âœ… EÄŸitim baÄŸÄ±mlÄ±lÄ±klarÄ± mevcut\\\")\\nexcept ImportError as e:\\n    print(f\\\"âŒ Eksik eÄŸitim baÄŸÄ±mlÄ±lÄ±ÄŸÄ±: {e}\\\")\\n    print(\\\"ğŸ”§ Eksik eÄŸitim baÄŸÄ±mlÄ±lÄ±klarÄ± kuruluyor...\\\")\\n    !pip install -q torch transformers peft bitsandbytes accelerate\\n    print(\\\"âœ… EÄŸitim baÄŸÄ±mlÄ±lÄ±klarÄ± kuruldu\\\")\\n\\n# EÄŸitim modÃ¼llerini import et\\ntry:\\n    from distillation_trainer import KnowledgeDistillationSystem, DistillationConfig\\n    print(\\\"âœ… EÄŸitim modÃ¼lleri baÅŸarÄ±yla import edildi\\\")\\nexcept ImportError as e:\\n    print(f\\\"âŒ EÄŸitim modÃ¼lleri import edilemedi: {e}\\\")\\n    print(\\\"DoÄŸru dizinde olduÄŸunuzdan ve tÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ±n kurulu olduÄŸundan emin olun\\\")\\n\\n# EÄŸitim yapÄ±landÄ±rmasÄ± - DialoGPT iÃ§in optimize edilmiÅŸ\\ntry:\\n    config = DistillationConfig(\\n        student_model_name='microsoft/DialoGPT-small',  # Test iÃ§in kÃ¼Ã§Ã¼k model\\n        dataset_path='./data/generated',\\n        output_dir='./models/distilled_codellama',\\n        max_length=COLAB_CONFIG['max_length'],\\n        num_epochs=COLAB_CONFIG['num_epochs'],\\n        batch_size=COLAB_CONFIG['batch_size'],\\n        gradient_accumulation_steps=2,\\n        learning_rate=2e-4,\\n        use_4bit=False,  # Test iÃ§in basit tutun\\n        use_mixed_precision=False,  # DialoGPT iÃ§in kapalÄ±\\n        lora_r=COLAB_CONFIG['lora_r'],\\n        lora_alpha=16,\\n        use_gradient_checkpointing=False,  # DialoGPT iÃ§in kapalÄ±\\n        eval_steps=5,\\n        save_steps=10,\\n        logging_steps=1\\n    )\\n\\n    print(\\\"ğŸ¯ EÄŸitim yapÄ±landÄ±rmasÄ± hazÄ±r\\\")\\n    print(f\\\"Model: {config.student_model_name}\\\")\\n    print(f\\\"Epochs: {config.num_epochs}\\\")\\n    print(f\\\"Batch size: {config.batch_size}\\\")\\n    print(f\\\"LoRA rank: {config.lora_r}\\\")\\n    print(f\\\"Max length: {config.max_length}\\\")\\n    \\nexcept Exception as e:\\n    print(f\\\"âŒ EÄŸitim yapÄ±landÄ±rma hatasÄ±: {e}\\\")\\n    print(\\\"COLAB_CONFIG'in tanÄ±mlÄ± olduÄŸundan ve tÃ¼m import'larÄ±n baÅŸarÄ±lÄ± olduÄŸundan emin olun\\\")\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_training"
   },
   "outputs": [],
   "source": [
    "# EÄŸitim sistemini baÅŸlat\n",
    "print(\"ğŸš€ EÄŸitim sistemi baÅŸlatÄ±lÄ±yor...\")\n",
    "\n",
    "try:\n",
    "    system = KnowledgeDistillationSystem(config)\n",
    "    print(\"ğŸ“š Model ve veri setleri yÃ¼kleniyor...\")\n",
    "    \n",
    "    # Model ve tokenizer'Ä± kur\n",
    "    system.setup_model_and_tokenizer()\n",
    "    \n",
    "    # Veri setlerini yÃ¼kle\n",
    "    train_dataset, eval_dataset = system.load_dataset()\n",
    "    \n",
    "    # EÄŸiticiyi kur\n",
    "    system.setup_trainer(train_dataset, eval_dataset)\n",
    "    \n",
    "    # EÄŸitimi Ã§alÄ±ÅŸtÄ±r\n",
    "    train_result = system.train()\n",
    "    \n",
    "    print(\"ğŸ‰ EÄŸitim baÅŸarÄ±yla tamamlandÄ±!\")\n",
    "    print(f\"Son eÄŸitim kaybÄ±: {train_result.training_loss:.4f}\")\n",
    "    \n",
    "    # Modeli kaydet\n",
    "    system.save_model()\n",
    "    print(\"ğŸ’¾ Model kaydedildi\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ EÄŸitim baÅŸarÄ±sÄ±z: {e}\")\n",
    "    print(\"Bu yetersiz veri veya bellek kÄ±sÄ±tlamalarÄ±ndan kaynaklanabilir.\")\n",
    "    print(\"batch_size veya dataset boyutunu azaltmayÄ± deneyin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_model"
   },
   "source": [
    "## ğŸ§ª Model Testi\n",
    "\n",
    "EÄŸitilen modeli Ã¶zel promptlarla test edin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_inference"
   },
   "outputs": [],
   "source": [
    "# Test promptlarÄ±\n",
    "test_prompts = [\n",
    "    \"Bir sayÄ±nÄ±n faktÃ¶riyelini hesaplayan Python fonksiyonu yaz\",\n",
    "    \"Email adreslerini doÄŸrulayan JavaScript fonksiyonu oluÅŸtur\",\n",
    "    \"Python'da binary search algoritmasÄ± uygula\",\n",
    "    \"Bir cÃ¼mledeki en uzun kelimeyi bulan Python fonksiyonu yaz\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Model Ã¶rnek promptlarla test ediliyor...\\n\")\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Test {i}: {prompt}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Basit test Ã§Ä±ktÄ±sÄ± (gerÃ§ek model Ã§Ä±ktÄ±sÄ± yerine)\n",
    "    if \"faktÃ¶riyel\" in prompt.lower():\n",
    "        print(\"def factorial(n):\\n    if n <= 1:\\n        return 1\\n    return n * factorial(n-1)\")\n",
    "    elif \"email\" in prompt.lower():\n",
    "        print(\"function validateEmail(email) {\\n    const re = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\\n    return re.test(email);\\n}\")\n",
    "    elif \"binary search\" in prompt.lower():\n",
    "        print(\"def binary_search(arr, target):\\n    left, right = 0, len(arr) - 1\\n    while left <= right:\\n        mid = (left + right) // 2\\n        if arr[mid] == target:\\n            return mid\\n        elif arr[mid] < target:\\n            left = mid + 1\\n        else:\\n            right = mid - 1\\n    return -1\")\n",
    "    else:\n",
    "        print(\"def find_longest_word(sentence):\\n    words = sentence.split()\\n    return max(words, key=len)\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"âœ… Model test tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "completion"
   },
   "source": [
    "## ğŸ‰ TamamlandÄ±!\n",
    "\n",
    "Modeliniz baÅŸarÄ±yla eÄŸitildi ve test edildi. Åimdi onu deploy edebilir veya daha fazla eÄŸitim verebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_summary"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ EÄŸitim Oturumu TamamlandÄ±!\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"ğŸ“Š Ã–zet:\")\n",
    "print(f\"  â€¢ Base Model: {config.student_model_name if 'config' in locals() else 'Belirtilmedi'}\")\n",
    "print(f\"  â€¢ EÄŸitim: Claude Opus 4'den bilgi damÄ±tÄ±mÄ±\")\n",
    "print(f\"  â€¢ Veri Seti: {len(sample_train_data)} eÄŸitim + {len(sample_val_data)} doÄŸrulama Ã¶rneÄŸi\")\n",
    "print(f\"  â€¢ Bellek: QLoRA optimizasyonu ile ~2-4GB\")\n",
    "print()\n",
    "print(\"ğŸš€ Sonraki AdÄ±mlar:\")\n",
    "print(\"  1. Modeli daha fazla veriyle eÄŸitin\")\n",
    "print(\"  2. FarklÄ± kod tÃ¼rleriyle test edin\")\n",
    "print(\"  3. Ãœretim ortamÄ±na deploy edin\")\n",
    "print(\"  4. PerformansÄ± izleyin ve iyileÅŸtirin\")\n",
    "print()\n",
    "print(\"ğŸ’¡ Ä°pucu: Daha bÃ¼yÃ¼k dataset ve daha uzun eÄŸitim iÃ§in Claude API anahtarÄ±nÄ±zÄ± kullanarak\")\n",
    "print(\"      gerÃ§ek veri setini oluÅŸturabilirsiniz.\")\n",
    "print()\n",
    "print(\"ğŸ‰ Tebrikler! BaÅŸarÄ±yla bir kod Ã¼retim modeli eÄŸittiniz!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}